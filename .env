OLLAMA_BASE_URL=http://localhost:11434 # the endpoint of the Ollama service, defaults to http://localhost:11434 if not set
OLLAMA_MODEL=deepseek-r1:8b # the name of the model to use, defaults to 'llama3.2' if not set

# Which search service to use, either 'duckduckgo', 'tavily', 'perplexity', Searxng
SEARCH_API='tavily'
# For Searxng search, defaults to http://localhost:8888
SEARXNG_URL=

# Web Search API Keys (choose one or both)
TAVILY_API_KEY=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      # Get your key at https://tavily.com

# LLM Configuration
LLM_PROVIDER=ollama          # Options: ollama, lmstudio

MAX_WEB_RESEARCH_LOOPS=3
FETCH_FULL_PAGE=True